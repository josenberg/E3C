{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6e5728e94a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecoded1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded1' is not defined"
     ]
    }
   ],
   "source": [
    "input_values = Input(shape=(32,))\n",
    "encoded = Dense(16, activation='relu')(input_values)\n",
    "decoded1 = Dense(32, activation='softmax')(encoded)\n",
    "decoded = Dense(32)(decoded1)\n",
    "\n",
    "\n",
    "autoencoder = Model(input_values, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_values, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(16,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14121\n"
     ]
    }
   ],
   "source": [
    "import MySQLdb\n",
    "db = MySQLdb.connect(host=\"143.106.73.88\",\n",
    "                         user=\"htc\",\n",
    "                         passwd=\"htc_123456\",\n",
    "                         db=\"hackthecampus\")\n",
    "\n",
    "cur = db.cursor()\n",
    "\n",
    "\n",
    "cur.execute(\"select lu.matricula,if(lu.lotacao = 'Aposentado\\r', 0, 1) ativo,bruto,indenizacoes,redutor, \"\n",
    "            \"descontos_legais,liquido,mes from \"\n",
    "            \"htc_folha_unicamp as fu join htc_lotacao_unicamp as lu on (fu.matricula = lu.matricula) \"\n",
    "            \"where ano=2016\")\n",
    "\n",
    "docentes = {}\n",
    "\n",
    "for row in cur.fetchall():\n",
    "    if row[0] not in docentes:\n",
    "        docentes[row[0]] = {\n",
    "            \"matricula\": row[0],\n",
    "            \"ativo\": row[1]\n",
    "        }\n",
    "    \n",
    "    docentes[row[0]][\"bruto_%d\"            % row[7]] = row[2]\n",
    "    docentes[row[0]][\"indenizacoes_%d\"     % row[7]] = row[3]\n",
    "    docentes[row[0]][\"redutor_%d\"          % row[7]] = row[4]\n",
    "    docentes[row[0]][\"descontos_legais_%d\" % row[7]] = row[5]\n",
    "    docentes[row[0]][\"liquido_%d\"          % row[7]] = row[6]\n",
    "    \n",
    "print len(docentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110001\n",
      "['matricula', 'redutor_5', 'redutor_4', 'redutor_6', 'redutor_1', 'redutor_3', 'redutor_2', 'bruto_4', 'bruto_5', 'bruto_6', 'bruto_1', 'bruto_2', 'bruto_3', 'descontos_legais_6', 'descontos_legais_5', 'descontos_legais_4', 'descontos_legais_3', 'descontos_legais_2', 'descontos_legais_1', 'ativo', 'liquido_5', 'liquido_4', 'liquido_3', 'liquido_2', 'liquido_1', 'liquido_6', 'indenizacoes_5', 'indenizacoes_4', 'indenizacoes_6', 'indenizacoes_1', 'indenizacoes_3', 'indenizacoes_2']\n"
     ]
    }
   ],
   "source": [
    "print docentes.keys()[0]\n",
    "print docentes[\"110001\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('110001', {'matricula': '110001', 'redutor_5': 0.0, 'redutor_4': 0.0, 'redutor_6': 0.0, 'redutor_1': 0.0, 'redutor_3': 0.0, 'redutor_2': 0.0, 'bruto_4': 17868.16, 'bruto_5': 18404.19, 'bruto_6': 18404.19, 'bruto_1': 17868.13, 'bruto_2': 17868.13, 'bruto_3': 17868.13, 'descontos_legais_6': 5975.47, 'descontos_legais_5': 5975.47, 'descontos_legais_4': 4708.73, 'descontos_legais_3': 5774.58, 'descontos_legais_2': 5774.58, 'descontos_legais_1': 5774.58, 'ativo': 1L, 'liquido_5': 12428.72, 'liquido_4': 16137.46, 'liquido_3': 12093.55, 'liquido_2': 12093.55, 'liquido_1': 12093.55, 'liquido_6': 12428.72, 'indenizacoes_5': 0.0, 'indenizacoes_4': 2978.03, 'indenizacoes_6': 0.0, 'indenizacoes_1': 0.0, 'indenizacoes_3': 0.0, 'indenizacoes_2': 0.0}), ('287142', {'matricula': '287142', 'redutor_5': 0.0, 'redutor_4': 0.0, 'redutor_6': 0.0, 'redutor_1': 0.0, 'redutor_3': 0.0, 'redutor_2': 0.0, 'bruto_4': 12180.29, 'bruto_5': 12545.71, 'bruto_6': 12545.71, 'bruto_1': 12180.3, 'bruto_2': 12180.29, 'bruto_3': 12180.29, 'descontos_legais_6': 2991.99, 'descontos_legais_5': 2991.99, 'descontos_legais_4': 2891.5, 'descontos_legais_3': 3210.51, 'descontos_legais_2': 2891.5, 'descontos_legais_1': 2093.88, 'ativo': 1L, 'liquido_5': 9553.72, 'liquido_4': 9288.79, 'liquido_3': 8969.78, 'liquido_2': 9288.79, 'liquido_1': 12116.47, 'liquido_6': 9553.72, 'indenizacoes_5': 0.0, 'indenizacoes_4': 0.0, 'indenizacoes_6': 0.0, 'indenizacoes_1': 2030.05, 'indenizacoes_3': 0.0, 'indenizacoes_2': 0.0})]\n"
     ]
    }
   ],
   "source": [
    "print docentes.items()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array( [[\n",
    "    x[\"matricula\"], x[\"ativo\"],\n",
    "    x.get(\"bruto_1\",0), x.get(\"indenizacoes_1\",0), x.get(\"redutor_1\",0), x.get(\"descontos_legais_1\",0), x.get(\"liquido_1\",0),\n",
    "    x.get(\"bruto_2\",0), x.get(\"indenizacoes_2\",0), x.get(\"redutor_2\",0), x.get(\"descontos_legais_2\",0), x.get(\"liquido_2\",0),\n",
    "    x.get(\"bruto_3\",0), x.get(\"indenizacoes_3\",0), x.get(\"redutor_3\",0), x.get(\"descontos_legais_3\",0), x.get(\"liquido_3\",0),\n",
    "    x.get(\"bruto_4\",0), x.get(\"indenizacoes_4\",0), x.get(\"redutor_4\",0), x.get(\"descontos_legais_4\",0), x.get(\"liquido_4\",0),\n",
    "    x.get(\"bruto_5\",0), x.get(\"indenizacoes_5\",0), x.get(\"redutor_5\",0), x.get(\"descontos_legais_5\",0), x.get(\"liquido_5\",0),\n",
    "    x.get(\"bruto_6\",0), x.get(\"indenizacoes_6\",0), x.get(\"redutor_6\",0), x.get(\"descontos_legais_6\",0), x.get(\"liquido_6\",0)\n",
    "    ]\n",
    "    for x in [y[1] for y in docentes.items()]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14121\n",
      "['287142' '1' '12180.3' '2030.05' '0.0' '2093.88' '12116.47' '12180.29'\n",
      " '0.0' '0.0' '2891.5' '9288.79' '12180.29' '0.0' '0.0' '3210.51' '8969.78'\n",
      " '12180.29' '0.0' '0.0' '2891.5' '9288.79' '12545.71' '0.0' '0.0' '2991.99'\n",
      " '9553.72' '12545.71' '0.0' '0.0' '2991.99' '9553.72']\n",
      "['217832' '0' '19368.49' '0.0' '0.0' '5975.09' '13393.4' '19368.49' '0.0'\n",
      " '0.0' '5975.09' '13393.4' '19439.84' '0.0' '0.0' '6001.83' '13438.01'\n",
      " '19439.84' '0.0' '0.0' '6001.83' '13438.01' '20001.36' '0.0' '0.0'\n",
      " '6212.26' '13789.1' '20001.36' '0.0' '0.0' '6212.26' '13789.1']\n"
     ]
    }
   ],
   "source": [
    "print len(a)\n",
    "\n",
    "train_data = a[:10000]\n",
    "\n",
    "print train_data[1]\n",
    "\n",
    "test_data = a[10000:]\n",
    "\n",
    "print test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 4121 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 0s - loss: 155564.0894 - val_loss: 155069.4389\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s - loss: 155446.7063 - val_loss: 155026.8968\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s - loss: 155242.1568 - val_loss: 154739.4334\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s - loss: 155058.4475 - val_loss: 154654.8714\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s - loss: 154946.4505 - val_loss: 154540.9282\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s - loss: 154814.4704 - val_loss: 154368.4778\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s - loss: 154589.6296 - val_loss: 153938.8121\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s - loss: 154220.3942 - val_loss: 153767.7584\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s - loss: 154105.6042 - val_loss: 153720.6273\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s - loss: 154094.8753 - val_loss: 153716.7156\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s - loss: 154094.1817 - val_loss: 153716.7108\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s - loss: 154094.1818 - val_loss: 153716.6933\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s - loss: 154094.1009 - val_loss: 153715.7974\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5026 - val_loss: 153715.7974\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5001 - val_loss: 153715.7974\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4973 - val_loss: 153715.7974\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4975 - val_loss: 153715.7974\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4991 - val_loss: 153715.7974\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5002 - val_loss: 153715.7974\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4979 - val_loss: 153715.7974\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5003 - val_loss: 153715.7974\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5010 - val_loss: 153715.7974\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4977 - val_loss: 153715.7974\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4998 - val_loss: 153715.7974\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4996 - val_loss: 153715.7974\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4994 - val_loss: 153715.7974\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4991 - val_loss: 153715.7974\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5004 - val_loss: 153715.7974\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4996 - val_loss: 153715.7974\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4974 - val_loss: 153715.7974\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5015 - val_loss: 153715.7974\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5001 - val_loss: 153715.7974\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4997 - val_loss: 153715.7974\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5007 - val_loss: 153715.7974\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5020 - val_loss: 153715.7974\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4979 - val_loss: 153715.7974\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5017 - val_loss: 153715.7974\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4995 - val_loss: 153715.7974\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5008 - val_loss: 153715.7974\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4972 - val_loss: 153715.7974\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5005 - val_loss: 153715.7974\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4974 - val_loss: 153715.7974\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4992 - val_loss: 153715.7974\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4982 - val_loss: 153715.7974\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5011 - val_loss: 153715.7974\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4992 - val_loss: 153715.7974\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5010 - val_loss: 153715.7974\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4980 - val_loss: 153715.7974\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4958 - val_loss: 153715.7974\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5005 - val_loss: 153715.7974\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4974 - val_loss: 153715.7974\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4973 - val_loss: 153715.7974\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4992 - val_loss: 153715.7974\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4980 - val_loss: 153715.7974\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4981 - val_loss: 153715.7974\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4999 - val_loss: 153715.7974\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4996 - val_loss: 153715.7974\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4984 - val_loss: 153715.7974\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4955 - val_loss: 153715.7974\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4999 - val_loss: 153715.7974\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4978 - val_loss: 153715.7974\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4991 - val_loss: 153715.7974\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4974 - val_loss: 153715.7974\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4997 - val_loss: 153715.7974\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4988 - val_loss: 153715.7974\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5003 - val_loss: 153715.7974\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4994 - val_loss: 153715.7974\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4943 - val_loss: 153715.7974\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5018 - val_loss: 153715.7974\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4993 - val_loss: 153715.7974\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4990 - val_loss: 153715.7974\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4982 - val_loss: 153715.7974\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4993 - val_loss: 153715.7974\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5027 - val_loss: 153715.7974\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4980 - val_loss: 153715.7974\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5011 - val_loss: 153715.7974\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s - loss: 154093.4969 - val_loss: 153715.7974\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4986 - val_loss: 153715.7974\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4962 - val_loss: 153715.7974\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4979 - val_loss: 153715.7974\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5007 - val_loss: 153715.7974\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4973 - val_loss: 153715.7974\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4982 - val_loss: 153715.7974\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4985 - val_loss: 153715.7974\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4990 - val_loss: 153715.7974\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4990 - val_loss: 153715.7974\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5035 - val_loss: 153715.7974\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4989 - val_loss: 153715.7974\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4986 - val_loss: 153715.7974\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5005 - val_loss: 153715.7974\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5002 - val_loss: 153715.7974\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4999 - val_loss: 153715.7974\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5017 - val_loss: 153715.7974\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4990 - val_loss: 153715.7974\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4982 - val_loss: 153715.7974\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4981 - val_loss: 153715.7974\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4977 - val_loss: 153715.7974\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.4996 - val_loss: 153715.7974\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5004 - val_loss: 153715.7974\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s - loss: 154093.5006 - val_loss: 153715.7974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6cb5eca10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(train_data, train_data,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_data,test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
